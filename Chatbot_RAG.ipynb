{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VgKmJ7C7pRam"
   },
   "source": [
    "### Auteur : Mohamed Lamine OULD BOUYA\n",
    "# Projet - Chatbot RAG : interroger vos PDF et pages web avec l’IA générative\n",
    "Objectif : construire un chatbot RAG (Retrieval-Augmented Generation) capable d’extraire le contenu de documents (PDF/sites web), de le vectoriser, puis de répondre de façon contextuelle via un modèle de langue. Une interface Gradio permet de tester le système facilement : charger un document ou une URL, poser une question, obtenir une réponse sourcée."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k24yAqGhpRar"
   },
   "source": [
    "## 1. Configuration de l'environnement\n",
    "\n",
    "Installation des bibliothèques nécessaires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\ouldb\\\\anaconda3\\\\python.exe'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.executable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai==0.28.1 in c:\\users\\ouldb\\anaconda3\\lib\\site-packages (0.28.1)\n",
      "Requirement already satisfied: python-dotenv in c:\\users\\ouldb\\anaconda3\\lib\\site-packages (0.21.0)\n",
      "Requirement already satisfied: bs4 in c:\\users\\ouldb\\anaconda3\\lib\\site-packages (0.0.2)\n",
      "Requirement already satisfied: PyPDF2 in c:\\users\\ouldb\\anaconda3\\lib\\site-packages (3.0.1)\n",
      "Requirement already satisfied: requests in c:\\users\\ouldb\\anaconda3\\lib\\site-packages (2.32.3)\n",
      "Requirement already satisfied: numpy in c:\\users\\ouldb\\anaconda3\\lib\\site-packages (1.26.4)\n",
      "Requirement already satisfied: gradio in c:\\users\\ouldb\\anaconda3\\lib\\site-packages (5.49.1)\n",
      "Requirement already satisfied: tqdm in c:\\users\\ouldb\\anaconda3\\lib\\site-packages (from openai==0.28.1) (4.66.5)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\ouldb\\anaconda3\\lib\\site-packages (from openai==0.28.1) (3.10.5)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\ouldb\\anaconda3\\lib\\site-packages (from bs4) (4.12.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\ouldb\\anaconda3\\lib\\site-packages (from requests) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\ouldb\\anaconda3\\lib\\site-packages (from requests) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\ouldb\\anaconda3\\lib\\site-packages (from requests) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ouldb\\anaconda3\\lib\\site-packages (from requests) (2024.12.14)\n",
      "Requirement already satisfied: aiofiles<25.0,>=22.0 in c:\\users\\ouldb\\anaconda3\\lib\\site-packages (from gradio) (24.1.0)\n",
      "Requirement already satisfied: anyio<5.0,>=3.0 in c:\\users\\ouldb\\anaconda3\\lib\\site-packages (from gradio) (4.2.0)\n",
      "Requirement already satisfied: brotli>=1.1.0 in c:\\users\\ouldb\\anaconda3\\lib\\site-packages (from gradio) (1.1.0)\n",
      "Requirement already satisfied: fastapi<1.0,>=0.115.2 in c:\\users\\ouldb\\anaconda3\\lib\\site-packages (from gradio) (0.120.0)\n",
      "Requirement already satisfied: ffmpy in c:\\users\\ouldb\\anaconda3\\lib\\site-packages (from gradio) (0.6.4)\n",
      "Requirement already satisfied: gradio-client==1.13.3 in c:\\users\\ouldb\\anaconda3\\lib\\site-packages (from gradio) (1.13.3)\n",
      "Requirement already satisfied: groovy~=0.1 in c:\\users\\ouldb\\anaconda3\\lib\\site-packages (from gradio) (0.1.2)\n",
      "Requirement already satisfied: httpx<1.0,>=0.24.1 in c:\\users\\ouldb\\anaconda3\\lib\\site-packages (from gradio) (0.27.0)\n",
      "Requirement already satisfied: huggingface-hub<2.0,>=0.33.5 in c:\\users\\ouldb\\anaconda3\\lib\\site-packages (from gradio) (0.36.0)\n",
      "Requirement already satisfied: jinja2<4.0 in c:\\users\\ouldb\\anaconda3\\lib\\site-packages (from gradio) (3.1.4)\n",
      "Requirement already satisfied: markupsafe<4.0,>=2.0 in c:\\users\\ouldb\\anaconda3\\lib\\site-packages (from gradio) (2.1.3)\n",
      "Requirement already satisfied: orjson~=3.0 in c:\\users\\ouldb\\anaconda3\\lib\\site-packages (from gradio) (3.11.4)\n",
      "Requirement already satisfied: packaging in c:\\users\\ouldb\\anaconda3\\lib\\site-packages (from gradio) (24.1)\n",
      "Requirement already satisfied: pandas<3.0,>=1.0 in c:\\users\\ouldb\\anaconda3\\lib\\site-packages (from gradio) (2.2.2)\n",
      "Requirement already satisfied: pillow<12.0,>=8.0 in c:\\users\\ouldb\\anaconda3\\lib\\site-packages (from gradio) (10.4.0)\n",
      "Requirement already satisfied: pydantic<2.12,>=2.0 in c:\\users\\ouldb\\anaconda3\\lib\\site-packages (from gradio) (2.8.2)\n",
      "Requirement already satisfied: pydub in c:\\users\\ouldb\\anaconda3\\lib\\site-packages (from gradio) (0.25.1)\n",
      "Requirement already satisfied: python-multipart>=0.0.18 in c:\\users\\ouldb\\anaconda3\\lib\\site-packages (from gradio) (0.0.20)\n",
      "Requirement already satisfied: pyyaml<7.0,>=5.0 in c:\\users\\ouldb\\anaconda3\\lib\\site-packages (from gradio) (6.0.1)\n",
      "Requirement already satisfied: ruff>=0.9.3 in c:\\users\\ouldb\\anaconda3\\lib\\site-packages (from gradio) (0.14.2)\n",
      "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in c:\\users\\ouldb\\anaconda3\\lib\\site-packages (from gradio) (0.1.7)\n",
      "Requirement already satisfied: semantic-version~=2.0 in c:\\users\\ouldb\\anaconda3\\lib\\site-packages (from gradio) (2.10.0)\n",
      "Requirement already satisfied: starlette<1.0,>=0.40.0 in c:\\users\\ouldb\\anaconda3\\lib\\site-packages (from gradio) (0.48.0)\n",
      "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in c:\\users\\ouldb\\anaconda3\\lib\\site-packages (from gradio) (0.13.3)\n",
      "Requirement already satisfied: typer<1.0,>=0.12 in c:\\users\\ouldb\\anaconda3\\lib\\site-packages (from gradio) (0.20.0)\n",
      "Requirement already satisfied: typing-extensions~=4.0 in c:\\users\\ouldb\\anaconda3\\lib\\site-packages (from gradio) (4.11.0)\n",
      "Requirement already satisfied: uvicorn>=0.14.0 in c:\\users\\ouldb\\anaconda3\\lib\\site-packages (from gradio) (0.38.0)\n",
      "Requirement already satisfied: fsspec in c:\\users\\ouldb\\anaconda3\\lib\\site-packages (from gradio-client==1.13.3->gradio) (2024.6.1)\n",
      "Requirement already satisfied: websockets<16.0,>=13.0 in c:\\users\\ouldb\\anaconda3\\lib\\site-packages (from gradio-client==1.13.3->gradio) (15.0.1)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\ouldb\\anaconda3\\lib\\site-packages (from anyio<5.0,>=3.0->gradio) (1.3.0)\n",
      "Requirement already satisfied: annotated-doc>=0.0.2 in c:\\users\\ouldb\\anaconda3\\lib\\site-packages (from fastapi<1.0,>=0.115.2->gradio) (0.0.3)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\ouldb\\anaconda3\\lib\\site-packages (from httpx<1.0,>=0.24.1->gradio) (1.0.2)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\ouldb\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx<1.0,>=0.24.1->gradio) (0.14.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\ouldb\\anaconda3\\lib\\site-packages (from huggingface-hub<2.0,>=0.33.5->gradio) (3.13.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\ouldb\\anaconda3\\lib\\site-packages (from pandas<3.0,>=1.0->gradio) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\ouldb\\anaconda3\\lib\\site-packages (from pandas<3.0,>=1.0->gradio) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\ouldb\\anaconda3\\lib\\site-packages (from pandas<3.0,>=1.0->gradio) (2023.3)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\ouldb\\anaconda3\\lib\\site-packages (from pydantic<2.12,>=2.0->gradio) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in c:\\users\\ouldb\\anaconda3\\lib\\site-packages (from pydantic<2.12,>=2.0->gradio) (2.20.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\ouldb\\appdata\\roaming\\python\\python312\\site-packages (from tqdm->openai==0.28.1) (0.4.6)\n",
      "Requirement already satisfied: click>=8.0.0 in c:\\users\\ouldb\\anaconda3\\lib\\site-packages (from typer<1.0,>=0.12->gradio) (8.1.7)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in c:\\users\\ouldb\\anaconda3\\lib\\site-packages (from typer<1.0,>=0.12->gradio) (1.5.0)\n",
      "Requirement already satisfied: rich>=10.11.0 in c:\\users\\ouldb\\anaconda3\\lib\\site-packages (from typer<1.0,>=0.12->gradio) (13.7.1)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\ouldb\\anaconda3\\lib\\site-packages (from aiohttp->openai==0.28.1) (2.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\ouldb\\anaconda3\\lib\\site-packages (from aiohttp->openai==0.28.1) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\ouldb\\anaconda3\\lib\\site-packages (from aiohttp->openai==0.28.1) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\ouldb\\anaconda3\\lib\\site-packages (from aiohttp->openai==0.28.1) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\ouldb\\anaconda3\\lib\\site-packages (from aiohttp->openai==0.28.1) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\ouldb\\anaconda3\\lib\\site-packages (from aiohttp->openai==0.28.1) (1.11.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\ouldb\\anaconda3\\lib\\site-packages (from beautifulsoup4->bs4) (2.5)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\ouldb\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.16.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\ouldb\\anaconda3\\lib\\site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\ouldb\\appdata\\roaming\\python\\python312\\site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\ouldb\\anaconda3\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install openai==0.28.1 python-dotenv bs4 PyPDF2 requests numpy gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clé OpenAI détectée ? oui\n"
     ]
    }
   ],
   "source": [
    "# Charger la clé depuis .env (sans l’écrire dans le code)\n",
    "import os\n",
    "try:\n",
    "    from dotenv import load_dotenv\n",
    "    load_dotenv()  # lit le fichier .env à la racine du projet\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "import openai\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# (optionnel) vérification sans afficher la clé\n",
    "print(\"Clé OpenAI détectée ?\", \"oui\" if os.getenv(\"OPENAI_API_KEY\") else \"non\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "executionInfo": {
     "elapsed": 10206,
     "status": "ok",
     "timestamp": 1740612653911,
     "user": {
      "displayName": "M-ING B",
      "userId": "01593093399446457799"
     },
     "user_tz": -60
    },
    "id": "NjIdupyGpRau"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import PyPDF2\n",
    "import openai\n",
    "import gradio as gr\n",
    "import os\n",
    "import numpy as np\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import PyPDF2\n",
    "import openai\n",
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mslgM3lQpRav"
   },
   "source": [
    "## 2. Modules d'extraction de contenu\n",
    "\n",
    "Création des fonction d'extraction du contenu de différentes sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "executionInfo": {
     "elapsed": 22,
     "status": "ok",
     "timestamp": 1740612660694,
     "user": {
      "displayName": "M-ING B",
      "userId": "01593093399446457799"
     },
     "user_tz": -60
    },
    "id": "8yvGnFrGpRav"
   },
   "outputs": [],
   "source": [
    "def scrape_website(url):\n",
    "    \"\"\"Scrape text content from a website\"\"\"\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        return ' '.join(soup.stripped_strings)\n",
    "    except Exception as e:\n",
    "        return f\"Error scraping website: {str(e)}\"\n",
    "\n",
    "def extract_pdf_content(pdf_path):\n",
    "    \"\"\"Extract text from a PDF file\"\"\"\n",
    "    try:\n",
    "        with open(pdf_path, 'rb') as file:\n",
    "            reader = PyPDF2.PdfReader(file)\n",
    "            return ' '.join(page.extract_text() for page in reader.pages)\n",
    "    except Exception as e:\n",
    "        return f\"Error processing PDF: {str(e)}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pXHCVTuMpRaw"
   },
   "source": [
    "## 3. Traitement du texte et génération d'embeddings\n",
    "\n",
    "Implémentation de découpage du texte et la génération d'embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1740612665006,
     "user": {
      "displayName": "M-ING B",
      "userId": "01593093399446457799"
     },
     "user_tz": -60
    },
    "id": "oZNXEGbvpRax"
   },
   "outputs": [],
   "source": [
    "def split_into_chunks(text, chunk_size=500):\n",
    "    \"\"\"Split text into manageable chunks\"\"\"\n",
    "    words = text.split()\n",
    "    return [' '.join(words[i:i+chunk_size]) for i in range(0, len(words), chunk_size)]\n",
    "\n",
    "def generate_embeddings(text):\n",
    "    \"\"\"Generate embeddings using OpenAI\"\"\"\n",
    "    response = openai.Embedding.create(\n",
    "        model=\"text-embedding-ada-002\",\n",
    "        input=text\n",
    "    )\n",
    "    return response['data'][0]['embedding']\n",
    "\n",
    "def cosine_similarity(vec1, vec2):\n",
    "    \"\"\"Compute cosine similarity between two vectors\"\"\"\n",
    "    return np.dot(vec1, vec2) / (np.linalg.norm(vec1) * np.linalg.norm(vec2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fH8_Ax2xpRax"
   },
   "source": [
    "## 4. Implémentation du cœur du chatbot RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1740612669493,
     "user": {
      "displayName": "M-ING B",
      "userId": "01593093399446457799"
     },
     "user_tz": -60
    },
    "id": "5BP5sdEIpRay"
   },
   "outputs": [],
   "source": [
    "class RAGChatbot:\n",
    "    def __init__(self):\n",
    "        self.chunks_with_embeddings = None\n",
    "\n",
    "    def load_from_url(self, url):\n",
    "        \"\"\"Load content from a website\"\"\"\n",
    "        content = scrape_website(url)\n",
    "        self._process_content(content)\n",
    "\n",
    "    def load_from_pdf(self, pdf_path):\n",
    "        \"\"\"Load content from a PDF\"\"\"\n",
    "        content = extract_pdf_content(pdf_path)\n",
    "        self._process_content(content)\n",
    "\n",
    "    def _process_content(self, content):\n",
    "        \"\"\"Process content into chunks and generate embeddings\"\"\"\n",
    "        chunks = split_into_chunks(content)\n",
    "        self.chunks_with_embeddings = [\n",
    "            {\"content\": chunk, \"embedding\": generate_embeddings(chunk)}\n",
    "            for chunk in chunks\n",
    "        ]\n",
    "\n",
    "    def find_relevant_chunk(self, query):\n",
    "        \"\"\"Find most relevant text chunk for a query\"\"\"\n",
    "        query_embedding = generate_embeddings(query)\n",
    "        similarities = [\n",
    "            (chunk[\"content\"], cosine_similarity(query_embedding, chunk[\"embedding\"]))\n",
    "            for chunk in self.chunks_with_embeddings\n",
    "        ]\n",
    "        return max(similarities, key=lambda x: x[1])[0]\n",
    "\n",
    "    def ask(self, query):\n",
    "        \"\"\"Generate response based on query and context\"\"\"\n",
    "        if not self.chunks_with_embeddings:\n",
    "            return \"Please load content first using load_from_url or load_from_pdf\"\n",
    "\n",
    "        relevant_chunk = self.find_relevant_chunk(query)\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are a helpful assistant using context to answer questions.\"},\n",
    "                {\"role\": \"user\", \"content\": f\"Context: {relevant_chunk}\\n\\nQuery: {query}\"}\n",
    "            ],\n",
    "            max_tokens=200\n",
    "        )\n",
    "        return response['choices'][0]['message']['content']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WOHn2-v-pRaz"
   },
   "source": [
    "## 5. Création d'une interface Web avec Gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1740612675312,
     "user": {
      "displayName": "M-ING B",
      "userId": "01593093399446457799"
     },
     "user_tz": -60
    },
    "id": "kUNYzV_JpRa0"
   },
   "outputs": [],
   "source": [
    "# --- ipython-input-7-7774a7eacb87 ---\n",
    "class RAGChatbotInterface:\n",
    "    def __init__(self):\n",
    "        self.chatbot = RAGChatbot()\n",
    "        self.chat_history = []\n",
    "\n",
    "    def process_file(self, file):\n",
    "        \"\"\"Process uploaded PDF file\"\"\"\n",
    "        try:\n",
    "            self.chatbot.load_from_pdf(file.name)\n",
    "            return \"PDF successfully loaded! You can now ask questions.\"\n",
    "        except Exception as e:\n",
    "            return f\"Error processing PDF: {str(e)}\"\n",
    "\n",
    "    def process_url(self, url):\n",
    "        \"\"\"Process website URL\"\"\"\n",
    "        try:\n",
    "            self.chatbot.load_from_url(url)\n",
    "            return \"Website content successfully loaded! You can now ask questions.\"\n",
    "        except Exception as e:\n",
    "            return f\"Error processing URL: {str(e)}\"\n",
    "\n",
    "    def chat(self, message, history):\n",
    "        \"\"\"Process chat message and update history\"\"\"\n",
    "        try:\n",
    "            response = self.chatbot.ask(message)\n",
    "            history.append((message, response))\n",
    "            return response, history\n",
    "        except Exception as e:\n",
    "            error_message = f\"Error generating response: {str(e)}\"\n",
    "            history.append((message, error_message))\n",
    "            return error_message, history\n",
    "\n",
    "    def launch_interface(self, share=True):\n",
    "        \"\"\"Create and launch Gradio interface\"\"\"\n",
    "        with gr.Blocks(title=\"RAG Chatbot\") as interface:\n",
    "            gr.Markdown(\"# 📚 RAG Chatbot: Learn from Any Document\")\n",
    "\n",
    "            with gr.Tab(\"PDF Input\"):\n",
    "                # Change 'type' to 'filepath' to get the file path\n",
    "                pdf_upload = gr.File(label=\"Upload PDF\", type=\"filepath\", file_types=[\".pdf\"])\n",
    "                pdf_status = gr.Textbox(label=\"PDF Status\", interactive=False)\n",
    "                pdf_upload.upload(fn=self.process_file, inputs=[pdf_upload], outputs=[pdf_status])\n",
    "\n",
    "            with gr.Tab(\"URL Input\"):\n",
    "                url_input = gr.Textbox(label=\"Enter Website URL\", placeholder=\"https://example.com\")\n",
    "                url_status = gr.Textbox(label=\"URL Status\", interactive=False)\n",
    "                url_button = gr.Button(\"Load Content\")\n",
    "                url_button.click(fn=self.process_url, inputs=[url_input], outputs=[url_status])\n",
    "\n",
    "            chatbot = gr.Chatbot(label=\"Chat with Your Document\", height=400)\n",
    "            msg = gr.Textbox(label=\"Your Question\", placeholder=\"Ask a question about the document...\")\n",
    "            clear = gr.Button(\"Clear Chat\")\n",
    "\n",
    "            msg.submit(fn=self.chat, inputs=[msg, chatbot], outputs=[msg, chatbot])\n",
    "            clear.click(lambda: None, None, chatbot, queue=False)\n",
    "\n",
    "        interface.launch(share=share)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a9NvffjppRa0"
   },
   "source": [
    "## 6. Lancement de l'interface du chatbot RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 645
    },
    "executionInfo": {
     "elapsed": 1440,
     "status": "ok",
     "timestamp": 1740612688535,
     "user": {
      "displayName": "M-ING B",
      "userId": "01593093399446457799"
     },
     "user_tz": -60
    },
    "id": "eG3T2eoOpRa1",
    "outputId": "94f6cad6-7047-432d-a078-e377265786c9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ouldb\\AppData\\Local\\Temp\\ipykernel_25272\\4037565904.py:51: UserWarning: You have not specified a value for the `type` parameter. Defaulting to the 'tuples' format for chatbot messages, but this is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style dictionaries with 'role' and 'content' keys.\n",
      "  chatbot = gr.Chatbot(label=\"Chat with Your Document\", height=400)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "* Running on public URL: https://920a1263bacdea6879.gradio.live\n",
      "\n",
      "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://920a1263bacdea6879.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Création et lancement de l'interface\n",
    "rag_interface = RAGChatbotInterface()\n",
    "rag_interface.launch_interface(share=True)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
