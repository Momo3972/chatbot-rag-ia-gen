{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VgKmJ7C7pRam"
   },
   "source": [
    "# Projet : Cr√©ation d‚Äôun Chatbot bas√© sur la RAG √† partir de documents PDF et cr√©ation d‚Äôune interface Web avec Gradio pour son d√©ploiement\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BoDcwNVPl1hU"
   },
   "source": [
    "## Etudiant UTT\n",
    "Pr√©nom : Mohamed Lamine\n",
    "Nom : OULD BOUYA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k24yAqGhpRar"
   },
   "source": [
    "## 1. Configuration de l'environnement\n",
    "\n",
    "Installation des biblioth√®ques n√©cessaires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 18389,
     "status": "ok",
     "timestamp": 1740612583415,
     "user": {
      "displayName": "M-ING B",
      "userId": "01593093399446457799"
     },
     "user_tz": -60
    },
    "id": "-35DM6qbpRas",
    "outputId": "06678f5a-ded8-4436-d0bf-def01ee31d23"
   },
   "outputs": [],
   "source": [
    "!pip install requests beautifulsoup4 PyPDF2 numpy gradio -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2908,
     "status": "ok",
     "timestamp": 1740612639783,
     "user": {
      "displayName": "M-ING B",
      "userId": "01593093399446457799"
     },
     "user_tz": -60
    },
    "id": "bfSQ3sfYrRxN",
    "outputId": "cadda717-2055-429e-86dc-a1d5d0e487b4"
   },
   "outputs": [],
   "source": [
    "#!openai migrate\n",
    "!pip install openai==0.28 -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.executable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install openai==0.28.1 python-dotenv bs4 PyPDF2 requests numpy gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger la cl√© depuis .env (sans l‚Äô√©crire dans le code)\n",
    "import os\n",
    "try:\n",
    "    from dotenv import load_dotenv\n",
    "    load_dotenv()  # lit le fichier .env √† la racine du projet\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "import openai\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# (optionnel) v√©rification sans afficher la cl√©\n",
    "print(\"Cl√© OpenAI d√©tect√©e ?\", \"oui\" if os.getenv(\"OPENAI_API_KEY\") else \"non\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 10206,
     "status": "ok",
     "timestamp": 1740612653911,
     "user": {
      "displayName": "M-ING B",
      "userId": "01593093399446457799"
     },
     "user_tz": -60
    },
    "id": "NjIdupyGpRau"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import PyPDF2\n",
    "import openai\n",
    "import gradio as gr\n",
    "import os\n",
    "import numpy as np\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import PyPDF2\n",
    "import openai\n",
    "import gradio as gr\n",
    "\n",
    "# Set OpenAI API Key\n",
    "openai.api_key = \"OPENAI_API_KEY\"  # Replace with your actual key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mslgM3lQpRav"
   },
   "source": [
    "## 2. Modules d'extraction de contenu\n",
    "\n",
    "Cr√©ation des fonction d'extraction du contenu de diff√©rentes sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 22,
     "status": "ok",
     "timestamp": 1740612660694,
     "user": {
      "displayName": "M-ING B",
      "userId": "01593093399446457799"
     },
     "user_tz": -60
    },
    "id": "8yvGnFrGpRav"
   },
   "outputs": [],
   "source": [
    "def scrape_website(url):\n",
    "    \"\"\"Scrape text content from a website\"\"\"\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        return ' '.join(soup.stripped_strings)\n",
    "    except Exception as e:\n",
    "        return f\"Error scraping website: {str(e)}\"\n",
    "\n",
    "def extract_pdf_content(pdf_path):\n",
    "    \"\"\"Extract text from a PDF file\"\"\"\n",
    "    try:\n",
    "        with open(pdf_path, 'rb') as file:\n",
    "            reader = PyPDF2.PdfReader(file)\n",
    "            return ' '.join(page.extract_text() for page in reader.pages)\n",
    "    except Exception as e:\n",
    "        return f\"Error processing PDF: {str(e)}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pXHCVTuMpRaw"
   },
   "source": [
    "## 3. Traitement du texte et g√©n√©ration d'embeddings\n",
    "\n",
    "Impl√©mentation de d√©coupage du texte et la g√©n√©ration d'embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1740612665006,
     "user": {
      "displayName": "M-ING B",
      "userId": "01593093399446457799"
     },
     "user_tz": -60
    },
    "id": "oZNXEGbvpRax"
   },
   "outputs": [],
   "source": [
    "def split_into_chunks(text, chunk_size=500):\n",
    "    \"\"\"Split text into manageable chunks\"\"\"\n",
    "    words = text.split()\n",
    "    return [' '.join(words[i:i+chunk_size]) for i in range(0, len(words), chunk_size)]\n",
    "\n",
    "def generate_embeddings(text):\n",
    "    \"\"\"Generate embeddings using OpenAI\"\"\"\n",
    "    response = openai.Embedding.create(\n",
    "        model=\"text-embedding-ada-002\",\n",
    "        input=text\n",
    "    )\n",
    "    return response['data'][0]['embedding']\n",
    "\n",
    "def cosine_similarity(vec1, vec2):\n",
    "    \"\"\"Compute cosine similarity between two vectors\"\"\"\n",
    "    return np.dot(vec1, vec2) / (np.linalg.norm(vec1) * np.linalg.norm(vec2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fH8_Ax2xpRax"
   },
   "source": [
    "## 4. Impl√©mentation du c≈ìur du chatbot RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1740612669493,
     "user": {
      "displayName": "M-ING B",
      "userId": "01593093399446457799"
     },
     "user_tz": -60
    },
    "id": "5BP5sdEIpRay"
   },
   "outputs": [],
   "source": [
    "class RAGChatbot:\n",
    "    def __init__(self):\n",
    "        self.chunks_with_embeddings = None\n",
    "\n",
    "    def load_from_url(self, url):\n",
    "        \"\"\"Load content from a website\"\"\"\n",
    "        content = scrape_website(url)\n",
    "        self._process_content(content)\n",
    "\n",
    "    def load_from_pdf(self, pdf_path):\n",
    "        \"\"\"Load content from a PDF\"\"\"\n",
    "        content = extract_pdf_content(pdf_path)\n",
    "        self._process_content(content)\n",
    "\n",
    "    def _process_content(self, content):\n",
    "        \"\"\"Process content into chunks and generate embeddings\"\"\"\n",
    "        chunks = split_into_chunks(content)\n",
    "        self.chunks_with_embeddings = [\n",
    "            {\"content\": chunk, \"embedding\": generate_embeddings(chunk)}\n",
    "            for chunk in chunks\n",
    "        ]\n",
    "\n",
    "    def find_relevant_chunk(self, query):\n",
    "        \"\"\"Find most relevant text chunk for a query\"\"\"\n",
    "        query_embedding = generate_embeddings(query)\n",
    "        similarities = [\n",
    "            (chunk[\"content\"], cosine_similarity(query_embedding, chunk[\"embedding\"]))\n",
    "            for chunk in self.chunks_with_embeddings\n",
    "        ]\n",
    "        return max(similarities, key=lambda x: x[1])[0]\n",
    "\n",
    "    def ask(self, query):\n",
    "        \"\"\"Generate response based on query and context\"\"\"\n",
    "        if not self.chunks_with_embeddings:\n",
    "            return \"Please load content first using load_from_url or load_from_pdf\"\n",
    "\n",
    "        relevant_chunk = self.find_relevant_chunk(query)\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are a helpful assistant using context to answer questions.\"},\n",
    "                {\"role\": \"user\", \"content\": f\"Context: {relevant_chunk}\\n\\nQuery: {query}\"}\n",
    "            ],\n",
    "            max_tokens=200\n",
    "        )\n",
    "        return response['choices'][0]['message']['content']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WOHn2-v-pRaz"
   },
   "source": [
    "## 5. Cr√©ation d'une interface Web avec Gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1740612675312,
     "user": {
      "displayName": "M-ING B",
      "userId": "01593093399446457799"
     },
     "user_tz": -60
    },
    "id": "kUNYzV_JpRa0"
   },
   "outputs": [],
   "source": [
    "# --- ipython-input-7-7774a7eacb87 ---\n",
    "class RAGChatbotInterface:\n",
    "    def __init__(self):\n",
    "        self.chatbot = RAGChatbot()\n",
    "        self.chat_history = []\n",
    "\n",
    "    def process_file(self, file):\n",
    "        \"\"\"Process uploaded PDF file\"\"\"\n",
    "        try:\n",
    "            self.chatbot.load_from_pdf(file.name)\n",
    "            return \"PDF successfully loaded! You can now ask questions.\"\n",
    "        except Exception as e:\n",
    "            return f\"Error processing PDF: {str(e)}\"\n",
    "\n",
    "    def process_url(self, url):\n",
    "        \"\"\"Process website URL\"\"\"\n",
    "        try:\n",
    "            self.chatbot.load_from_url(url)\n",
    "            return \"Website content successfully loaded! You can now ask questions.\"\n",
    "        except Exception as e:\n",
    "            return f\"Error processing URL: {str(e)}\"\n",
    "\n",
    "    def chat(self, message, history):\n",
    "        \"\"\"Process chat message and update history\"\"\"\n",
    "        try:\n",
    "            response = self.chatbot.ask(message)\n",
    "            history.append((message, response))\n",
    "            return response, history\n",
    "        except Exception as e:\n",
    "            error_message = f\"Error generating response: {str(e)}\"\n",
    "            history.append((message, error_message))\n",
    "            return error_message, history\n",
    "\n",
    "    def launch_interface(self, share=True):\n",
    "        \"\"\"Create and launch Gradio interface\"\"\"\n",
    "        with gr.Blocks(title=\"RAG Chatbot\") as interface:\n",
    "            gr.Markdown(\"# üìö RAG Chatbot: Learn from Any Document\")\n",
    "\n",
    "            with gr.Tab(\"PDF Input\"):\n",
    "                # Change 'type' to 'filepath' to get the file path\n",
    "                pdf_upload = gr.File(label=\"Upload PDF\", type=\"filepath\", file_types=[\".pdf\"])\n",
    "                pdf_status = gr.Textbox(label=\"PDF Status\", interactive=False)\n",
    "                pdf_upload.upload(fn=self.process_file, inputs=[pdf_upload], outputs=[pdf_status])\n",
    "\n",
    "            with gr.Tab(\"URL Input\"):\n",
    "                url_input = gr.Textbox(label=\"Enter Website URL\", placeholder=\"https://example.com\")\n",
    "                url_status = gr.Textbox(label=\"URL Status\", interactive=False)\n",
    "                url_button = gr.Button(\"Load Content\")\n",
    "                url_button.click(fn=self.process_url, inputs=[url_input], outputs=[url_status])\n",
    "\n",
    "            chatbot = gr.Chatbot(label=\"Chat with Your Document\", height=400)\n",
    "            msg = gr.Textbox(label=\"Your Question\", placeholder=\"Ask a question about the document...\")\n",
    "            clear = gr.Button(\"Clear Chat\")\n",
    "\n",
    "            msg.submit(fn=self.chat, inputs=[msg, chatbot], outputs=[msg, chatbot])\n",
    "            clear.click(lambda: None, None, chatbot, queue=False)\n",
    "\n",
    "        interface.launch(share=share)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a9NvffjppRa0"
   },
   "source": [
    "## 6. Lancement de l'interface du chatbot RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 645
    },
    "executionInfo": {
     "elapsed": 1440,
     "status": "ok",
     "timestamp": 1740612688535,
     "user": {
      "displayName": "M-ING B",
      "userId": "01593093399446457799"
     },
     "user_tz": -60
    },
    "id": "eG3T2eoOpRa1",
    "outputId": "94f6cad6-7047-432d-a078-e377265786c9"
   },
   "outputs": [],
   "source": [
    "# Cr√©ation et lancement de l'interface\n",
    "rag_interface = RAGChatbotInterface()\n",
    "rag_interface.launch_interface(share=True)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
