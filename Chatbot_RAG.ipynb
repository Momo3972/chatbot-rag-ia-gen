{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VgKmJ7C7pRam"
   },
   "source": [
    "# Projet : Création d’un Chatbot basé sur la RAG à partir de documents PDF et création d’une interface Web avec Gradio pour son déploiement\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BoDcwNVPl1hU"
   },
   "source": [
    "## Etudiant UTT\n",
    "Prénom : Mohamed Lamine\n",
    "Nom : OULD BOUYA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k24yAqGhpRar"
   },
   "source": [
    "## 1. Configuration de l'environnement\n",
    "\n",
    "Installation des bibliothèques nécessaires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 18389,
     "status": "ok",
     "timestamp": 1740612583415,
     "user": {
      "displayName": "M-ING B",
      "userId": "01593093399446457799"
     },
     "user_tz": -60
    },
    "id": "-35DM6qbpRas",
    "outputId": "06678f5a-ded8-4436-d0bf-def01ee31d23"
   },
   "outputs": [],
   "source": [
    "!pip install requests beautifulsoup4 PyPDF2 numpy gradio -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2908,
     "status": "ok",
     "timestamp": 1740612639783,
     "user": {
      "displayName": "M-ING B",
      "userId": "01593093399446457799"
     },
     "user_tz": -60
    },
    "id": "bfSQ3sfYrRxN",
    "outputId": "cadda717-2055-429e-86dc-a1d5d0e487b4"
   },
   "outputs": [],
   "source": [
    "#!openai migrate\n",
    "!pip install openai==0.28 -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.executable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install openai==0.28.1 python-dotenv bs4 PyPDF2 requests numpy gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger la clé depuis .env (sans l’écrire dans le code)\n",
    "import os\n",
    "try:\n",
    "    from dotenv import load_dotenv\n",
    "    load_dotenv()  # lit le fichier .env à la racine du projet\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "import openai\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# (optionnel) vérification sans afficher la clé\n",
    "print(\"Clé OpenAI détectée ?\", \"oui\" if os.getenv(\"OPENAI_API_KEY\") else \"non\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 10206,
     "status": "ok",
     "timestamp": 1740612653911,
     "user": {
      "displayName": "M-ING B",
      "userId": "01593093399446457799"
     },
     "user_tz": -60
    },
    "id": "NjIdupyGpRau"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import PyPDF2\n",
    "import openai\n",
    "import gradio as gr\n",
    "import os\n",
    "import numpy as np\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import PyPDF2\n",
    "import openai\n",
    "import gradio as gr\n",
    "\n",
    "# Set OpenAI API Key\n",
    "openai.api_key = \"OPENAI_API_KEY\"  # Replace with your actual key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mslgM3lQpRav"
   },
   "source": [
    "## 2. Modules d'extraction de contenu\n",
    "\n",
    "Création des fonction d'extraction du contenu de différentes sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 22,
     "status": "ok",
     "timestamp": 1740612660694,
     "user": {
      "displayName": "M-ING B",
      "userId": "01593093399446457799"
     },
     "user_tz": -60
    },
    "id": "8yvGnFrGpRav"
   },
   "outputs": [],
   "source": [
    "def scrape_website(url):\n",
    "    \"\"\"Scrape text content from a website\"\"\"\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        return ' '.join(soup.stripped_strings)\n",
    "    except Exception as e:\n",
    "        return f\"Error scraping website: {str(e)}\"\n",
    "\n",
    "def extract_pdf_content(pdf_path):\n",
    "    \"\"\"Extract text from a PDF file\"\"\"\n",
    "    try:\n",
    "        with open(pdf_path, 'rb') as file:\n",
    "            reader = PyPDF2.PdfReader(file)\n",
    "            return ' '.join(page.extract_text() for page in reader.pages)\n",
    "    except Exception as e:\n",
    "        return f\"Error processing PDF: {str(e)}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pXHCVTuMpRaw"
   },
   "source": [
    "## 3. Traitement du texte et génération d'embeddings\n",
    "\n",
    "Implémentation de découpage du texte et la génération d'embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1740612665006,
     "user": {
      "displayName": "M-ING B",
      "userId": "01593093399446457799"
     },
     "user_tz": -60
    },
    "id": "oZNXEGbvpRax"
   },
   "outputs": [],
   "source": [
    "def split_into_chunks(text, chunk_size=500):\n",
    "    \"\"\"Split text into manageable chunks\"\"\"\n",
    "    words = text.split()\n",
    "    return [' '.join(words[i:i+chunk_size]) for i in range(0, len(words), chunk_size)]\n",
    "\n",
    "def generate_embeddings(text):\n",
    "    \"\"\"Generate embeddings using OpenAI\"\"\"\n",
    "    response = openai.Embedding.create(\n",
    "        model=\"text-embedding-ada-002\",\n",
    "        input=text\n",
    "    )\n",
    "    return response['data'][0]['embedding']\n",
    "\n",
    "def cosine_similarity(vec1, vec2):\n",
    "    \"\"\"Compute cosine similarity between two vectors\"\"\"\n",
    "    return np.dot(vec1, vec2) / (np.linalg.norm(vec1) * np.linalg.norm(vec2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fH8_Ax2xpRax"
   },
   "source": [
    "## 4. Implémentation du cœur du chatbot RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1740612669493,
     "user": {
      "displayName": "M-ING B",
      "userId": "01593093399446457799"
     },
     "user_tz": -60
    },
    "id": "5BP5sdEIpRay"
   },
   "outputs": [],
   "source": [
    "class RAGChatbot:\n",
    "    def __init__(self):\n",
    "        self.chunks_with_embeddings = None\n",
    "\n",
    "    def load_from_url(self, url):\n",
    "        \"\"\"Load content from a website\"\"\"\n",
    "        content = scrape_website(url)\n",
    "        self._process_content(content)\n",
    "\n",
    "    def load_from_pdf(self, pdf_path):\n",
    "        \"\"\"Load content from a PDF\"\"\"\n",
    "        content = extract_pdf_content(pdf_path)\n",
    "        self._process_content(content)\n",
    "\n",
    "    def _process_content(self, content):\n",
    "        \"\"\"Process content into chunks and generate embeddings\"\"\"\n",
    "        chunks = split_into_chunks(content)\n",
    "        self.chunks_with_embeddings = [\n",
    "            {\"content\": chunk, \"embedding\": generate_embeddings(chunk)}\n",
    "            for chunk in chunks\n",
    "        ]\n",
    "\n",
    "    def find_relevant_chunk(self, query):\n",
    "        \"\"\"Find most relevant text chunk for a query\"\"\"\n",
    "        query_embedding = generate_embeddings(query)\n",
    "        similarities = [\n",
    "            (chunk[\"content\"], cosine_similarity(query_embedding, chunk[\"embedding\"]))\n",
    "            for chunk in self.chunks_with_embeddings\n",
    "        ]\n",
    "        return max(similarities, key=lambda x: x[1])[0]\n",
    "\n",
    "    def ask(self, query):\n",
    "        \"\"\"Generate response based on query and context\"\"\"\n",
    "        if not self.chunks_with_embeddings:\n",
    "            return \"Please load content first using load_from_url or load_from_pdf\"\n",
    "\n",
    "        relevant_chunk = self.find_relevant_chunk(query)\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are a helpful assistant using context to answer questions.\"},\n",
    "                {\"role\": \"user\", \"content\": f\"Context: {relevant_chunk}\\n\\nQuery: {query}\"}\n",
    "            ],\n",
    "            max_tokens=200\n",
    "        )\n",
    "        return response['choices'][0]['message']['content']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WOHn2-v-pRaz"
   },
   "source": [
    "## 5. Création d'une interface Web avec Gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1740612675312,
     "user": {
      "displayName": "M-ING B",
      "userId": "01593093399446457799"
     },
     "user_tz": -60
    },
    "id": "kUNYzV_JpRa0"
   },
   "outputs": [],
   "source": [
    "# --- ipython-input-7-7774a7eacb87 ---\n",
    "class RAGChatbotInterface:\n",
    "    def __init__(self):\n",
    "        self.chatbot = RAGChatbot()\n",
    "        self.chat_history = []\n",
    "\n",
    "    def process_file(self, file):\n",
    "        \"\"\"Process uploaded PDF file\"\"\"\n",
    "        try:\n",
    "            self.chatbot.load_from_pdf(file.name)\n",
    "            return \"PDF successfully loaded! You can now ask questions.\"\n",
    "        except Exception as e:\n",
    "            return f\"Error processing PDF: {str(e)}\"\n",
    "\n",
    "    def process_url(self, url):\n",
    "        \"\"\"Process website URL\"\"\"\n",
    "        try:\n",
    "            self.chatbot.load_from_url(url)\n",
    "            return \"Website content successfully loaded! You can now ask questions.\"\n",
    "        except Exception as e:\n",
    "            return f\"Error processing URL: {str(e)}\"\n",
    "\n",
    "    def chat(self, message, history):\n",
    "        \"\"\"Process chat message and update history\"\"\"\n",
    "        try:\n",
    "            response = self.chatbot.ask(message)\n",
    "            history.append((message, response))\n",
    "            return response, history\n",
    "        except Exception as e:\n",
    "            error_message = f\"Error generating response: {str(e)}\"\n",
    "            history.append((message, error_message))\n",
    "            return error_message, history\n",
    "\n",
    "    def launch_interface(self, share=True):\n",
    "        \"\"\"Create and launch Gradio interface\"\"\"\n",
    "        with gr.Blocks(title=\"RAG Chatbot\") as interface:\n",
    "            gr.Markdown(\"# 📚 RAG Chatbot: Learn from Any Document\")\n",
    "\n",
    "            with gr.Tab(\"PDF Input\"):\n",
    "                # Change 'type' to 'filepath' to get the file path\n",
    "                pdf_upload = gr.File(label=\"Upload PDF\", type=\"filepath\", file_types=[\".pdf\"])\n",
    "                pdf_status = gr.Textbox(label=\"PDF Status\", interactive=False)\n",
    "                pdf_upload.upload(fn=self.process_file, inputs=[pdf_upload], outputs=[pdf_status])\n",
    "\n",
    "            with gr.Tab(\"URL Input\"):\n",
    "                url_input = gr.Textbox(label=\"Enter Website URL\", placeholder=\"https://example.com\")\n",
    "                url_status = gr.Textbox(label=\"URL Status\", interactive=False)\n",
    "                url_button = gr.Button(\"Load Content\")\n",
    "                url_button.click(fn=self.process_url, inputs=[url_input], outputs=[url_status])\n",
    "\n",
    "            chatbot = gr.Chatbot(label=\"Chat with Your Document\", height=400)\n",
    "            msg = gr.Textbox(label=\"Your Question\", placeholder=\"Ask a question about the document...\")\n",
    "            clear = gr.Button(\"Clear Chat\")\n",
    "\n",
    "            msg.submit(fn=self.chat, inputs=[msg, chatbot], outputs=[msg, chatbot])\n",
    "            clear.click(lambda: None, None, chatbot, queue=False)\n",
    "\n",
    "        interface.launch(share=share)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a9NvffjppRa0"
   },
   "source": [
    "## 6. Lancement de l'interface du chatbot RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 645
    },
    "executionInfo": {
     "elapsed": 1440,
     "status": "ok",
     "timestamp": 1740612688535,
     "user": {
      "displayName": "M-ING B",
      "userId": "01593093399446457799"
     },
     "user_tz": -60
    },
    "id": "eG3T2eoOpRa1",
    "outputId": "94f6cad6-7047-432d-a078-e377265786c9"
   },
   "outputs": [],
   "source": [
    "# Création et lancement de l'interface\n",
    "rag_interface = RAGChatbotInterface()\n",
    "rag_interface.launch_interface(share=True)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
